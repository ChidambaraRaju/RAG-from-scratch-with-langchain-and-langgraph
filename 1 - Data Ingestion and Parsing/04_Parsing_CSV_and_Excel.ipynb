{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5194098-b80c-4e89-8b43-b1d62054ff1a",
   "metadata": {},
   "source": [
    "### 📖 Where We Are\n",
    "\n",
    "**So far**, we have built a solid foundation for handling unstructured and semi-structured documents:\n",
    "1.  **Notebook 1**: Covered `.txt` files and text splitting fundamentals.\n",
    "2.  **Notebook 2**: Tackled the complexities of PDFs with specialized loaders and cleaning pipelines.\n",
    "3.  **Notebook 3**: Explored `.docx` files, highlighting the difference between simple text extraction and element-aware parsing with `Unstructured`.\n",
    "\n",
    "**In this notebook**, we pivot to a new and important category: **structured data**. We'll focus on the most common formats, **CSV and Excel files**. The challenge here is different: instead of just extracting text, we need to thoughtfully convert rows and columns of data into a format that a language model can understand and reason about."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1085508d",
   "metadata": {},
   "source": [
    "### 1. CSV And Excel files - Structured Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a0c84f-a7b2-4d1e-8e43-8f6453531f94",
   "metadata": {},
   "source": [
    "Working with structured data like CSV and Excel for RAG requires a shift in mindset. Our goal is to convert tabular data into a descriptive, text-based format. \n",
    "\n",
    "**Analogy**: Imagine you have a spreadsheet of product inventory. If you just feed the raw numbers `[Laptop, 999.99, 50]` to a language model, it lacks context. A better approach is to translate each row into a human-readable sentence or paragraph, like: *\"We have a Laptop from the Electronics category, which costs $999.99 and has 50 units in stock.\"* \n",
    "\n",
    "This process of converting structured rows into unstructured text is fundamental to making tabular data useful in a RAG system. We'll start by creating some sample files to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "716573cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas is the essential library for working with structured data in Python.\n",
    "import pandas as pd\n",
    "# os is used for interacting with the file system, like creating directories.\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e365c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory to store our sample files.\n",
    "os.makedirs(\"data/structured_files\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "834384b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample dataset of products as a Python dictionary.\n",
    "data = {\n",
    "    'Product': ['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Webcam'],\n",
    "    'Category': ['Electronics', 'Accessories', 'Accessories', 'Electronics', 'Electronics'],\n",
    "    'Price': [999.99, 29.99, 79.99, 299.99, 89.99],\n",
    "    'Stock': [50, 200, 150, 75, 100],\n",
    "    'Description': [\n",
    "        'High-performance laptop with 16GB RAM and 512GB SSD',\n",
    "        'Wireless optical mouse with ergonomic design',\n",
    "        'Mechanical keyboard with RGB backlighting',\n",
    "        '27-inch 4K monitor with HDR support',\n",
    "        '1080p webcam with noise cancellation'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Use pandas to convert the dictionary into a DataFrame, which is a tabular data structure.\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file. `index=False` prevents pandas from writing row indices into the file.\n",
    "df.to_csv('data/structured_files/products.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8561ccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create an Excel file with multiple sheets, we use the `ExcelWriter`.\n",
    "with pd.ExcelWriter('data/structured_files/inventory.xlsx') as writer:\n",
    "    # Write the main products DataFrame to a sheet named 'Products'.\n",
    "    df.to_excel(writer, sheet_name='Products', index=False)\n",
    "    \n",
    "    # Create a second, summary DataFrame.\n",
    "    summary_data = {\n",
    "        'Category': ['Electronics', 'Accessories'],\n",
    "        'Total_Items': [3, 2],\n",
    "        'Total_Value': [1389.97, 109.98]\n",
    "    }\n",
    "    # Write the summary data to a different sheet named 'Summary'.\n",
    "    pd.DataFrame(summary_data).to_excel(writer, sheet_name='Summary', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1b9cb7",
   "metadata": {},
   "source": [
    "## 2. CSV Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc5d39c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSVLoader: The standard LangChain loader for CSVs, treating each row as a document.\n",
    "# UnstructuredCSVLoader: A more advanced loader that can identify tables within a CSV.\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_community.document_loaders import UnstructuredCSVLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8471b072-f8b1-419b-b9f1-f050b1d3d65b",
   "metadata": {},
   "source": [
    "### Method 1: `CSVLoader` (Row-Based)\n",
    "\n",
    "This is the most straightforward way to load a CSV. It iterates through the file and creates **one `Document` for each row**. The `page_content` of each document is a simple string where each column and its value are listed, separated by newlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aba7566a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1️⃣ CSVLoader - Row-based Documents\n",
      "Loaded 5 documents (one per row)\n",
      "\n",
      "First document:\n",
      "Content: Product: Laptop\n",
      "Category: Electronics\n",
      "Price: 999.99\n",
      "Stock: 50\n",
      "Description: High-performance laptop with 16GB RAM and 512GB SSD\n",
      "Metadata: {'source': 'data/structured_files/products.csv', 'row': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"1️⃣ CSVLoader - Row-based Documents\")\n",
    "csv_loader = CSVLoader(\n",
    "    file_path='data/structured_files/products.csv',\n",
    "    encoding='utf-8',\n",
    "    # csv_args allows you to pass arguments directly to Python's csv.reader.\n",
    "    csv_args={\n",
    "        'delimiter': ',',\n",
    "        'quotechar': '\"',\n",
    "    }\n",
    ")\n",
    "\n",
    "csv_docs = csv_loader.load()\n",
    "\n",
    "print(f\"Loaded {len(csv_docs)} documents (one per row)\")\n",
    "print(\"\\nFirst document:\")\n",
    "# Note the format: 'column_name: value'.\n",
    "print(f\"Content: {csv_docs[0].page_content}\")\n",
    "# The metadata includes the source and the original row number.\n",
    "print(f\"Metadata: {csv_docs[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f99849-5e72-463d-82c8-7c858b1ab6b9",
   "metadata": {},
   "source": [
    "### Method 2: Custom CSV Processing (Intelligent Approach)\n",
    "\n",
    "While `CSVLoader` is easy, it's not always optimal for RAG. The default `page_content` format is generic. For better results, we can create a custom processing function using `pandas` to format each row into a more descriptive, natural-language-friendly string and to add much richer metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2180b064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2️⃣ Custom CSV Processing\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "print(\"\\n2️⃣ Custom CSV Processing\")\n",
    "def process_csv_intelligently(filepath: str) -> List[Document]:\n",
    "    \"\"\"Reads a CSV and creates a well-formatted Document for each row with rich metadata.\"\"\"\n",
    "    # Read the CSV into a pandas DataFrame.\n",
    "    df = pd.read_csv(filepath)\n",
    "    documents = []\n",
    "    \n",
    "    # Iterate over each row in the DataFrame.\n",
    "    for idx, row in df.iterrows():\n",
    "        # Use an f-string to create a descriptive, human-readable format for the content.\n",
    "        content = f\"\"\"Product Information:\n",
    "        Name: {row['Product']}\n",
    "        Category: {row['Category']}\n",
    "        Price: ${row['Price']}\n",
    "        Stock: {row['Stock']} units\n",
    "        Description: {row['Description']}\"\"\"\n",
    "        \n",
    "        # Create a LangChain Document with this formatted content.\n",
    "        doc = Document(\n",
    "            page_content=content,\n",
    "            # Create rich, structured metadata. This is incredibly useful for filtering during retrieval.\n",
    "            metadata={\n",
    "                'source': filepath,\n",
    "                'row_index': idx,\n",
    "                'product_name': row['Product'],\n",
    "                'category': row['Category'],\n",
    "                'price': row['Price'],\n",
    "                'data_type': 'product_info' # Add a custom tag for the data type.\n",
    "            }\n",
    "        )\n",
    "        documents.append(doc)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3958d0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'data/structured_files/products.csv', 'row_index': 0, 'product_name': 'Laptop', 'category': 'Electronics', 'price': 999.99, 'data_type': 'product_info'}, page_content='Product Information:\\n        Name: Laptop\\n        Category: Electronics\\n        Price: $999.99\\n        Stock: 50 units\\n        Description: High-performance laptop with 16GB RAM and 512GB SSD')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run our custom function and inspect the output. Note the cleaner content and richer metadata.\n",
    "intelligent_csv_docs = process_csv_intelligently('data/structured_files/products.csv')\n",
    "intelligent_csv_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e3b0a2-ad44-78ca-93d7-e44d371ba53d",
   "metadata": {},
   "source": [
    "### 📊 CSV Processing Strategy Comparison\n",
    "\n",
    "| Strategy | Page Content | Metadata | Best For |\n",
    "| :--- | :--- | :---: | :--- |\n",
    "| **`CSVLoader`** | `key: value` pairs | Basic (source, row) | Quick loading when you just need the raw row data. |\n",
    "| **Custom Function** | Formatted, natural language | **Rich & Custom** | **RAG systems**. Creates context-rich documents and allows for powerful metadata filtering (e.g., \"find products where `category` is 'Electronics' and `price` is less than $100\"). |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c09b236",
   "metadata": {},
   "source": [
    "### 3. Excel Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b320d771-48d6-4448-9c4c-31d77a83d973",
   "metadata": {},
   "source": [
    "Excel files are similar to CSVs but with the added complexity of potentially having **multiple sheets**. A robust Excel parser needs to be able to handle this. We will again compare a custom `pandas` approach with the `Unstructured` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a514e486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1️⃣ Pandas-based Excel Processing\n"
     ]
    }
   ],
   "source": [
    "print(\"1️⃣ Pandas-based Excel Processing\")\n",
    "def process_excel_with_pandas(filepath: str) -> List[Document]:\n",
    "    \"\"\"Processes an Excel file, creating one Document per sheet.\"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    # Use pd.ExcelFile to efficiently read the file and get sheet names.\n",
    "    excel_file = pd.ExcelFile(filepath)\n",
    "    \n",
    "    # Loop through each sheet in the Excel file.\n",
    "    for sheet_name in excel_file.sheet_names:\n",
    "        # Read the specific sheet into a DataFrame.\n",
    "        df = pd.read_excel(filepath, sheet_name=sheet_name)\n",
    "        \n",
    "        # Convert the entire DataFrame to a string, which will serve as the page_content.\n",
    "        # This preserves the full table structure in a text format.\n",
    "        sheet_content = df.to_string(index=False)\n",
    "        \n",
    "        doc = Document(\n",
    "            page_content=sheet_content,\n",
    "            metadata={\n",
    "                'source': filepath,\n",
    "                'sheet_name': sheet_name,\n",
    "                'num_rows': len(df),\n",
    "                'num_columns': len(df.columns),\n",
    "                'data_type': 'excel_sheet' # Custom tag\n",
    "            }\n",
    "        )\n",
    "        documents.append(doc)\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b426233e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2 sheets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'data/structured_files/inventory.xlsx', 'sheet_name': 'Products', 'num_rows': 5, 'num_columns': 5, 'data_type': 'excel_sheet'}, page_content=' Product    Category  Price  Stock                                         Description\\n  Laptop Electronics 999.99     50 High-performance laptop with 16GB RAM and 512GB SSD\\n   Mouse Accessories  29.99    200        Wireless optical mouse with ergonomic design\\nKeyboard Accessories  79.99    150           Mechanical keyboard with RGB backlighting\\n Monitor Electronics 299.99     75                 27-inch 4K monitor with HDR support\\n  Webcam Electronics  89.99    100                1080p webcam with noise cancellation')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run our custom Excel processing function.\n",
    "excel_docs = process_excel_with_pandas('data/structured_files/inventory.xlsx')\n",
    "print(f\"Processed {len(excel_docs)} sheets\")\n",
    "excel_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a567d1c-8f1d-4008-8e6c-c76b97621f3f",
   "metadata": {},
   "source": [
    "### Method 2: `UnstructuredExcelLoader`\n",
    "\n",
    "Just as with Word documents, the `Unstructured` library provides a powerful loader for Excel. In `elements` mode, it will parse the file and identify tables on each sheet, returning each table as a separate `Document`. This is very effective for extracting the core data from each sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24103792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2️⃣ UnstructuredExcelLoader\n",
      "  Loaded 2 elements (tables).\n",
      "  First element's metadata: {'source': 'data/structured_files/inventory.xlsx', 'file_directory': 'data/structured_files', 'filename': 'inventory.xlsx', 'last_modified': '2025-08-19T23:03:26', 'page_name': 'Products', 'page_number': 1, 'text_as_html': '<table><tr><td>Product</td><td>Category</td><td>Price</td><td>Stock</td><td>Description</td></tr><tr><td>Laptop</td><td>Electronics</td><td>999.99</td><td>50</td><td>High-performance laptop with 16GB RAM and 512GB SSD</td></tr><tr><td>Mouse</td><td>Accessories</td><td>29.99</td><td>200</td><td>Wireless optical mouse with ergonomic design</td></tr><tr><td>Keyboard</td><td>Accessories</td><td>79.99</td><td>150</td><td>Mechanical keyboard with RGB backlighting</td></tr><tr><td>Monitor</td><td>Electronics</td><td>299.99</td><td>75</td><td>27-inch 4K monitor with HDR support</td></tr><tr><td>Webcam</td><td>Electronics</td><td>89.99</td><td>100</td><td>1080p webcam with noise cancellation</td></tr></table>', 'languages': ['eng'], 'filetype': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'category': 'Table', 'element_id': '6c3514d8bca67e1cbfa020192b595264'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import UnstructuredExcelLoader\n",
    "\n",
    "print(\"\\n2️⃣ UnstructuredExcelLoader\")\n",
    "try:\n",
    "    # Initialize the loader in 'elements' mode to identify tables.\n",
    "    excel_loader = UnstructuredExcelLoader(\n",
    "        'data/structured_files/inventory.xlsx',\n",
    "        mode=\"elements\"\n",
    "    )\n",
    "    unstructured_excel_docs = excel_loader.load()\n",
    "    print(f\"  Loaded {len(unstructured_excel_docs)} elements (tables).\")\n",
    "    # The metadata is very rich, even including an HTML representation of the table.\n",
    "    print(f\"  First element's metadata: {unstructured_excel_docs[0].metadata}\")\n",
    "except Exception as e:\n",
    "    print(f\"  Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f280a82b-5813-4c90-99c5-0370483ba645",
   "metadata": {},
   "source": [
    "### 🔑 Key Takeaways\n",
    "\n",
    "* **Translate Structure to Text**: The core challenge with structured data (CSV/Excel) is to convert tabular rows and columns into a descriptive, natural language format that an LLM can effectively use.\n",
    "* **Customization is Key for RAG**: For both CSV and Excel, creating a custom processing pipeline with `pandas` is superior to basic loaders for RAG. It allows you to precisely control the `page_content` format and, more importantly, create rich, filterable metadata from the columns.\n",
    "* **Handle Multiple Sheets**: Excel files often contain multiple sheets. Your processing strategy must be sheet-aware, treating each sheet as a separate context or document.\n",
    "* **Row vs. Table Granularity**: You can choose your strategy based on your needs. For answering questions about a single item (e.g., \"What is the price of a Laptop?\"), row-based documents are effective. For questions about the entire dataset (e.g., \"Summarize the products in the electronics category\"), a document representing the whole table or sheet is better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ultimate RAG Bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
