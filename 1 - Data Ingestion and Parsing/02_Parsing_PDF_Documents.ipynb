{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6f9b8c0-f1c5-430c-8f49-5915d0382029",
   "metadata": {},
   "source": [
    "### ðŸ“– Where We Are\n",
    "\n",
    "**So far**, we've learned the fundamentals of data ingestion using simple text files. We covered:\n",
    "- The basic structure of a LangChain `Document`.\n",
    "- How to load single and multiple text files using `TextLoader` and `DirectoryLoader`.\n",
    "- Why text splitting is crucial and how to use different splitters like `RecursiveCharacterTextSplitter`.\n",
    "\n",
    "**In this notebook**, we'll tackle a much more common and complex data source: **PDF files**. We will explore different loaders, compare their strengths, and build a robust pipeline to handle the unique challenges that PDFs present."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbafa8a2",
   "metadata": {},
   "source": [
    "## 1. Loading PDF Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96d740c-3964-4e76-857e-7c00e19a4e21",
   "metadata": {},
   "source": [
    "PDFs are one of the most common document formats, but they can be tricky. Unlike a plain `.txt` file, a PDF is a complex format that can contain text, images, tables, and complex layouts. Extracting text accurately is the first major hurdle.\n",
    "\n",
    "**Analogy**: Think of a `.txt` file as a simple typed letter, where all the text is in a clear, linear order. A PDF, on the other hand, is like a glossy magazine page. The text might be in different columns, wrapped around images, or have distinct headers and footers. A PDF loader is like a person whose job is to read that magazine page and transcribe just the text, ignoring the irrelevant parts and trying to keep the reading order logical.\n",
    "\n",
    "LangChain offers several loaders for this task, each with its own strengths. We'll look at the two most popular ones: `PyPDFLoader` and `PyMuPDFLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "188d295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary PDF loaders from the langchain_community library.\n",
    "from langchain_community.document_loaders import (\n",
    "    PyPDFLoader,    # Uses the `pypdf` library\n",
    "    PyMuPDFLoader   # Uses the `PyMuPDF` library, which is generally faster\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270d49f1-a128-498c-9b16-e41c4aa99c15",
   "metadata": {},
   "source": [
    "### Method 1: `PyPDFLoader`\n",
    "\n",
    "This is the standard, easy-to-use loader for PDFs. It loads a PDF and splits it by page, creating one `Document` object for each page. It's a great starting point for simple, text-based PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7d065cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1ï¸âƒ£ PyPDFLoader\n",
      "  Loaded 15 pages\n",
      "  Page 1 content: Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and...\n",
      "  Metadata: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'author': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'data/pdf/attention.pdf', 'total_pages': 15, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "print(\"1ï¸âƒ£ PyPDFLoader\")\n",
    "\n",
    "# A try-except block is used to gracefully handle potential errors, like the file not being found.\n",
    "try:\n",
    "    # Initialize the loader with the path to your PDF file.\n",
    "    pypdf_loader=PyPDFLoader(\"data/pdf/attention.pdf\")\n",
    "    \n",
    "    # The .load() method reads and parses the PDF.\n",
    "    # It returns a list where each element is a Document object representing a page.\n",
    "    pypdf_docs=pypdf_loader.load()\n",
    "    \n",
    "    print(f\"  Loaded {len(pypdf_docs)} pages\")\n",
    "    print(f\"  Page 1 content: {pypdf_docs[0].page_content[:100]}...\")\n",
    "    \n",
    "    # Each Document contains metadata, including the source file and the page number.\n",
    "    print(f\"  Metadata: {pypdf_docs[0].metadata}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67041fa3-9993-455b-80a2-f61e27e80ac7",
   "metadata": {},
   "source": [
    "### Method 2: `PyMuPDFLoader`\n",
    "\n",
    "This loader uses the `PyMuPDF` library, which is known for its speed and efficiency. It often provides faster loading times and can sometimes extract text more cleanly than `PyPDFLoader`. It also splits the PDF by page, creating one `Document` per page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49a55f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2ï¸âƒ£ PyMuPDFLoader (Fast and accurate)\n",
      "  Loaded 15 pages\n",
      "  Page 1 Metadata: {'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-04-10T21:11:43+00:00', 'source': 'data/pdf/attention.pdf', 'file_path': 'data/pdf/attention.pdf', 'total_pages': 15, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2024-04-10T21:11:43+00:00', 'trapped': '', 'modDate': 'D:20240410211143Z', 'creationDate': 'D:20240410211143Z', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2ï¸âƒ£ PyMuPDFLoader (Fast and accurate)\")\n",
    "try:\n",
    "    # Initialize the loader, similar to PyPDFLoader.\n",
    "    pymupdf_loader = PyMuPDFLoader(\"data/pdf/attention.pdf\")\n",
    "    pymupdf_docs = pymupdf_loader.load()\n",
    "    \n",
    "    print(f\"  Loaded {len(pymupdf_docs)} pages\")\n",
    "    # The metadata extracted by PyMuPDFLoader can be more detailed.\n",
    "    print(f\"  Page 1 Metadata: {pymupdf_docs[0].metadata}\")\n",
    "except Exception as e:\n",
    "    print(f\"  Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a2a468-18e3-4610-ad44-783ca89369d7",
   "metadata": {},
   "source": [
    "### ðŸ“Š PDF Loader Comparison\n",
    "\n",
    "| Loader | Speed | Text Extraction | Dependencies | Use Case |\n",
    "| :--- | :---: | :---: | :---: | :--- |\n",
    "| **`PyPDFLoader`** | Standard | Good | `pypdf` | Simple, reliable option for standard text-based PDFs. |\n",
    "| **`PyMuPDFLoader`**| **Fast** | **Excellent** | `PyMuPDF` | Best for performance and when dealing with more complex layouts. Recommended for most use cases. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dc686a",
   "metadata": {},
   "source": [
    "## 2. Handling PDF Challenges & Building a Processing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f516d25e-38e8-4679-b883-7313a968a356",
   "metadata": {},
   "source": [
    "Simply loading a PDF is often not enough. Raw extracted text can be messy and contain artifacts that will confuse a language model.\n",
    "\n",
    "Common issues include:\n",
    "- **Ligatures**: Characters like 'ï¬' and 'ï¬‚' that are actually single characters in the PDF but represent two letters ('fi', 'fl').\n",
    "- **Excessive Whitespace**: Unnecessary newlines, spaces, and tabs that break the flow of sentences.\n",
    "- **Headers/Footers**: Repetitive text on each page (e.g., \"Page 5 of 12\") that adds no value.\n",
    "- **Hyphenation**: Words broken across lines with a hyphen (e.g., \"perform-\" on one line and \"ance\" on the next).\n",
    "\n",
    "To handle this, we need to create a post-processing step to clean the text before splitting it into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3e65e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE:\n",
      "\"Company Financial Report\\n\\n\\n    The ï¬nancial performance for ï¬scal year 2024\\n    shows signiï¬cant growth in proï¬tability.\\n\\n    Revenue increased by 25%.\\n\\nThe company's efï¬ciency improved due to workï¬‚ow\\noptimization.\\n\\nPage 1 of 10\\n\"\n",
      "\n",
      "AFTER:\n",
      "\"Company Financial Report The financial performance for fiscal year 2024 shows significant growth in profitability. Revenue increased by 25%. The company's efficiency improved due to workflow optimization. Page 1 of 10\"\n"
     ]
    }
   ],
   "source": [
    "# Example of raw, messy text that might be extracted from a PDF\n",
    "raw_pdf_text = \"\"\"Company Financial Report\n",
    "\n",
    "\n",
    "    The ï¬nancial performance for ï¬scal year 2024\n",
    "    shows signiï¬cant growth in proï¬tability.\n",
    "    \n",
    "    Revenue increased by 25%.\n",
    "    \n",
    "The company's efï¬ciency improved due to workï¬‚ow\n",
    "optimization.\n",
    "\n",
    "Page 1 of 10\n",
    "\"\"\"\n",
    "\n",
    "# Define a simple cleaning function to address common issues\n",
    "def clean_text(text):\n",
    "    # 1. Replace ligatures with their standard two-character counterparts.\n",
    "    text = text.replace(\"ï¬\", \"fi\").replace(\"ï¬‚\", \"fl\")\n",
    "    \n",
    "    # 2. Consolidate multiple whitespace characters into a single space.\n",
    "    # .split() breaks the string by whitespace, and ' '.join() reassembles it with single spaces.\n",
    "    text = \" \".join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "cleaned = clean_text(raw_pdf_text)\n",
    "print(\"BEFORE:\")\n",
    "# The repr() function shows the string with its raw formatting, including newlines (\\n).\n",
    "print(repr(raw_pdf_text))\n",
    "print(\"\\nAFTER:\")\n",
    "print(repr(cleaned))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e68d06-1ddf-44e2-9b26-a320c8c156c7",
   "metadata": {},
   "source": [
    "### Building a `SmartPDFProcessor` Class\n",
    "\n",
    "Instead of running these steps manually each time, we can encapsulate this logic into a reusable class. This makes our data ingestion pipeline cleaner, more robust, and easier to manage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab67c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll need Document for type hinting and List for defining return types.\n",
    "from langchain_core.documents import Document\n",
    "from typing import List\n",
    "# We will use PyPDFLoader and a text splitter.\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "class SmartPDFProcessor:\n",
    "    \"\"\"An advanced PDF processor that loads, cleans, and chunks PDFs, while enhancing metadata.\"\"\"\n",
    "    def __init__(self, chunk_size: int = 1000, chunk_overlap: int = 100):\n",
    "        \"\"\"Initializes the processor with a text splitter configuration.\"\"\"\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            # Using a simple space separator can be effective after our cleaning removes complex whitespace.\n",
    "            separators=[\" \"],\n",
    "        )\n",
    "\n",
    "    def process_pdf(self, pdf_path: str) -> List[Document]:\n",
    "        \"\"\"The main method to process a PDF file.\"\"\"\n",
    "        # 1. Load the PDF using PyPDFLoader.\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        pages = loader.load()\n",
    "\n",
    "        # This list will hold all the final, processed chunks.\n",
    "        processed_chunks = []\n",
    "\n",
    "        # 2. Iterate through each loaded page.\n",
    "        for page_num, page in enumerate(pages):\n",
    "            # 3. Clean the text content of the page.\n",
    "            cleaned_text = self._clean_text(page.page_content)\n",
    "\n",
    "            # 4. Skip pages that are nearly empty after cleaning to avoid creating useless chunks.\n",
    "            if len(cleaned_text.strip()) < 50:\n",
    "                continue\n",
    "\n",
    "            # 5. Split the cleaned text into chunks. We use `create_documents` to keep metadata.\n",
    "            chunks = self.text_splitter.create_documents(\n",
    "                texts=[cleaned_text],\n",
    "                # Enhance the metadata for each chunk.\n",
    "                metadatas=[{\n",
    "                    **page.metadata,  # Inherit original metadata from the page.\n",
    "                    \"page\": page_num + 1, # Add a 1-based page number.\n",
    "                    \"total_pages\": len(pages),\n",
    "                    \"chunk_method\": \"smart_pdf_processor\", # Add a custom tag.\n",
    "                    \"char_count\": len(cleaned_text)\n",
    "                }]\n",
    "            )\n",
    "            \n",
    "            # 6. Add the chunks from this page to our main list.\n",
    "            processed_chunks.extend(chunks)\n",
    "\n",
    "        return processed_chunks\n",
    "\n",
    "    def _clean_text(self, text: str) -> str:\n",
    "        \"\"\"A private helper method to clean extracted text.\"\"\"\n",
    "        # Consolidate whitespace.\n",
    "        text = \" \".join(text.split())\n",
    "        # Fix common PDF extraction issues (ligatures).\n",
    "        text = text.replace(\"ï¬\", \"fi\").replace(\"ï¬‚\", \"fl\")\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ab4143d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed into 49 smart chunks\n",
      "\n",
      "Sample chunk metadata:\n",
      "  producer: pdfTeX-1.40.25\n",
      "  creator: LaTeX with hyperref\n",
      "  creationdate: 2024-04-10T21:11:43+00:00\n",
      "  author: \n",
      "  keywords: \n",
      "  moddate: 2024-04-10T21:11:43+00:00\n",
      "  ptex.fullbanner: This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5\n",
      "  subject: \n",
      "  title: \n",
      "  trapped: /False\n",
      "  source: data/pdf/attention.pdf\n",
      "  total_pages: 15\n",
      "  page: 1\n",
      "  page_label: 1\n",
      "  chunk_method: smart_pdf_processor\n",
      "  char_count: 2857\n"
     ]
    }
   ],
   "source": [
    "# Instantiate our custom processor.\n",
    "processor = SmartPDFProcessor()\n",
    "\n",
    "try:\n",
    "    # Run the entire pipeline on our PDF file.\n",
    "    smart_chunks = processor.process_pdf(\"data/pdf/attention.pdf\")\n",
    "    print(f\"Processed into {len(smart_chunks)} smart chunks\")\n",
    "\n",
    "    # Inspect the metadata of the first chunk to see our enhancements.\n",
    "    if smart_chunks:\n",
    "        print(\"\\nSample chunk metadata:\")\n",
    "        for key, value in smart_chunks[0].metadata.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Processing error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893d5a49-963d-42ac-9f4a-8742d1377b3b",
   "metadata": {},
   "source": [
    "### ðŸ”‘ Key Takeaways\n",
    "\n",
    "* **PDFs are Complex**: Unlike plain text, PDFs require specialized loaders. The text extraction can be imperfect, containing artifacts like ligatures and strange whitespace.\n",
    "* **Choose the Right Loader**: `PyMuPDFLoader` is generally recommended for its speed and performance, but `PyPDFLoader` is a solid, simple alternative.\n",
    "* **Cleaning is Crucial**: Always inspect the raw text extracted from your documents. A simple cleaning function to handle whitespace and text artifacts significantly improves the quality of your data.\n",
    "* **Build a Pipeline**: For a robust RAG system, encapsulate your ingestion logic (load -> clean -> split) into a reusable class. This makes your process more reliable, manageable, and allows you to easily add enhancements like custom metadata."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ultimate RAG Bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
